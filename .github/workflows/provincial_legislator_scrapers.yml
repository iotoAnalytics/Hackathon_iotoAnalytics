# Github Workflow to automatically scrape ca_legislator data every month
# 
# Author: Kevin N.

name: ca_provincial_legislator scrapers

on:
#   schedule:
#     - cron: "0 0 1 * *" # Runs every month
  push:
    branches:
      - main
    
jobs:
  build:
    runs-on: windows-latest # Needs to run on windows...
    permissions:
      id-token: write
      contents: read
    steps:
      - name: setup chrome
        uses: browser-actions/setup-chrome@latest

      - name: checkout repo content
        uses: actions/checkout@v2
        
      - name: Public IP
        id: ip
        uses: haythem/public-ip@v1.2
        
      - name: configure AWS credentials
        uses: aws-actions/configure-aws-credentials@master
        with:
          aws-region: us-west-2
          aws-access-key-id: ${{ secrets.AWS_RDS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_RDS_SECRET_ACCESS_KEY }}
        
      - name: Allow Security group rule to connect Github Actions to PostgresSQL
        run: |
          aws ec2 authorize-security-group-ingress --group-name openparlPermittedIPAddresses --protocol tcp --port 5432 --cidr ${{ steps.ip.outputs.ipv4 }}/32

      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8' # Might work with later versions, but currently 3.8 required to run the scrapers
        
      - name: install python packages
        run: |
          python -m pip install --upgrade pip
          pip3 install -r requirements.txt

      # This is basically a powershell script. If the environment changes to ubuntu or mac, this will need to be changed.
      # The script starts by opening chrome once, because this needs to be done for the webdriver to install the correct chrome driver.
      # - name: execute py script 
      #   run: |
      #     Start-Process -FilePath 'C:\Program Files\Google\Chrome\Application\chrome.exe'\
      #     Start-Sleep -s 10
      #     $files = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *_legislator_scraper.py
      #     foreach ($file in $files) {
      #     echo "Running File: " $file.FullName
      #     python $file
      #     if ($LASTEXITCODE -ne 0) {
      #       Exit 1
      #     }
      #     echo "Complete running " $file.FullName
      #     }

      - name: temporary testing script
        run: |
          Start-Process -FilePath 'C:\Program Files\Google\Chrome\Application\chrome.exe'\
          Start-Sleep -s 10
          $file1 = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *ns_legislator_scraper.py
          $file2 = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *nt_legislator_scraper.py
          $file3 = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *nu_legislator_scraper.py
          $file4 = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *on_legislator_scraper.py
          $file5 = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *pe_legislator_scraper.py
          $file6 = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *qc_legislator_scraper.py
          $file7 = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *sk_legislator_scraper.py
          $file8 = Get-ChildItem -Path scrapers\ca\ca-provinces -Recurse *yt_legislator_scraper.py
          
          $files = @($file1, $file2, $file3, $file4, $file5, $file6, $file7, $file8)
          
          foreach ($file in $files) {
          echo "Running File: " $file.FullName
          python $file
          if ($LASTEXITCODE -ne 0) {
            Exit 1
          }
          echo "Complete running " $file.FullName
          }
          
      - name: Deny Security group rule to connect Github Actions to PostgresSQL
        run: |
          aws ec2 revoke-security-group-ingress --group-name openparlPermittedIPAddresses --protocol tcp --port 5432 --cidr ${{ steps.ip.outputs.ipv4 }}/32
        if: always()
